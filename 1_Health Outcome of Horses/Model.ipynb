{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the dataset zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "!kaggle competitions download -c playground-series-s3e22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_path = 'playground-series-s3e22.zip'\n",
    "with ZipFile(file_path, 'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Training and Test csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the singleton values from train_df which are not in test_df and also Encoding the outcome column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['peristalsis'] != 'distend_small']\n",
    "train_df = train_df[train_df['nasogastric_reflux'] != 'slight']\n",
    "train_df = train_df[train_df['rectal_exam_feces'] != 'serosanguious']\n",
    "train_df['outcome'].replace({'died': 0, 'euthanized': 1, 'lived': 2}, inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two dataframes precisely from training and test dataframes by dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = train_df.drop(columns=['id', 'hospital_number', 'outcome'], axis = 1)\n",
    "df2 = test_df.drop(columns=['id', 'hospital_number'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting out all the necessary information from both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "numerical_features = []\n",
    "for cols in df2:\n",
    "    if df2[cols].dtype == 'object':\n",
    "        categorical_features.append(cols)\n",
    "    else:\n",
    "        numerical_features.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheking the null values from both the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the categorical column null values with mode and numerical column nul values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df1.columns:\n",
    "    if col in categorical_features:\n",
    "        mode_value = df1[col].mode()[0]  \n",
    "        df1[col].fillna(mode_value, inplace=True)  \n",
    "    else:\n",
    "        median_value = df1[col].median()  \n",
    "        df1[col].fillna(median_value, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.columns:\n",
    "    if col in categorical_features:\n",
    "        mode_value = df2[col].mode()[0]  \n",
    "        df2[col].fillna(mode_value, inplace=True)  \n",
    "    else:\n",
    "        median_value = df2[col].median()  \n",
    "        df2[col].fillna(median_value, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df1[['rectal_temp', 'pulse', 'respiratory_rate', 'packed_cell_volume', 'total_protein']])\n",
    "plt.title('Box Plot of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df1[['rectal_temp', 'pulse', 'respiratory_rate', 'packed_cell_volume', 'total_protein']], bins=20, kde=True)\n",
    "plt.title('Distribution of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in categorical_features:\n",
    "    print(cols, df1[cols].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in categorical_features:\n",
    "    print(cols, df2[cols].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Mapping of all the categorical columns in both the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'surgery': {'yes': 0, 'no': 1},\n",
    "    'age': {'adult': 0, 'young': 1},\n",
    "    'temp_of_extremities': {'cool': 0, 'cold': 1, 'normal': 2, 'warm': 3},\n",
    "    'peripheral_pulse': {'reduced': 0, 'normal': 1, 'absent': 2, 'increased': 3},\n",
    "    'mucous_membrane': {\n",
    "        'dark_cyanotic': 0, 'pale_cyanotic': 1, 'pale_pink': 2,\n",
    "        'normal_pink': 3, 'bright_pink': 4, 'bright_red': 5\n",
    "    },\n",
    "    'capillary_refill_time': {'more_3_sec': 0, 'less_3_sec': 1, '3': 2},\n",
    "    'pain': {'depressed': 0, 'mild_pain': 1, 'extreme_pain': 2, 'alert': 3, 'severe_pain': 4, 'slight': 5, 'moderate': 5},\n",
    "    'peristalsis': {'absent': 0, 'hypomotile': 1, 'normal': 2, 'hypermotile': 3, 'distend_small': 4},\n",
    "    'abdominal_distention': {'slight': 0, 'moderate': 1, 'none': 2, 'severe': 3},\n",
    "    'nasogastric_tube': {'slight': 0, 'none': 1, 'significant': 2},\n",
    "    'nasogastric_reflux': {'less_1_liter': 0, 'more_1_liter': 1, 'none': 2, 'slight': 3},\n",
    "    'rectal_exam_feces': {'decreased': 0, 'absent': 1, 'normal': 2, 'increased': 3, 'serosanguious': 4},\n",
    "    'abdomen': {'distend_small': 0, 'distend_large': 1, 'normal': 2, 'firm': 3, 'other': 4},\n",
    "    'abdomo_appearance': {'serosanguious': 0, 'cloudy': 1, 'clear': 2},\n",
    "    'surgical_lesion': {'yes': 0, 'no': 1},\n",
    "    'cp_data': {'no': 0, 'yes': 1}\n",
    "}\n",
    "\n",
    "\n",
    "df1.replace(category_mapping, inplace=True)\n",
    "df2.replace(category_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Train and Test nd arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = df1\n",
    "test_X = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling using Column Transformer and Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('StandardScaling', StandardScaler(), numerical_features)\n",
    "], remainder='passthrough')\n",
    "train_X = ct.fit_transform(train_X)\n",
    "test_X = ct.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['outcome']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the all the models being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting (XGBoost)': XGBClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting (LightGBM)': LGBMClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting (CatBoost)': CatBoostClassifier(iterations=100, random_state=42, verbose=0),\n",
    "    'Support Vector Machine (SVM)': SVC(kernel='rbf', C=1.0, random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors (KNN)': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Ensemble': AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acc_score, precision_score as prec_score, recall_score as rec_score, f1_score as f1\n",
    "\n",
    "model_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model_name = list(models.keys())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    model_list.append(model_name)\n",
    "    accuracy = acc_score(y_test, y_test_pred)\n",
    "    precision = prec_score(y_test, y_test_pred, average='weighted')\n",
    "    recall = rec_score(y_test, y_test_pred, average='weighted')\n",
    "    f1_score = f1(y_test, y_test_pred, average='weighted')\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(f\"{model_name} has scores as: Accuracy - {accuracy}, Precision - {precision}, Recall - {recall}, F1 Score - {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation = pd.DataFrame({'Model Name':model_list, 'Accuracy':accuracy_list})\n",
    "model_evaluation = model_evaluation.sort_values(by=['Accuracy'], ascending=False)\n",
    "model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the best model and taking out the predictions of the test_df and saving the predictions into a csv file to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier()\n",
    "best_model.fit(train_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(test_X)\n",
    "prediction_mapping = {0: 'died', 1: 'euthanized', 2: 'lived'}\n",
    "predicted_labels = [prediction_mapping[pred] for pred in predictions]\n",
    "submission_df = pd.DataFrame({'Predicted_Outcome': predicted_labels})\n",
    "start_id = 1235\n",
    "ids = range(start_id, start_id + len(predicted_labels))\n",
    "submission_df = pd.DataFrame({'id': ids, 'Outcome': predicted_labels})\n",
    "submission_df.to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
